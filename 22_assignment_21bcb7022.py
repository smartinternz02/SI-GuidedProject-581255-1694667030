# -*- coding: utf-8 -*-
"""22_assignment_21BCB7022.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oj5WOdcn_BFuN1EGZAYlZ-jawDy58ml6

NAME:Thakur Akshath Singh

REG NO: 21BCB7022

1.Download the Employee Attrition Dataset

https://www.kaggle.com/datasets/patelprashant/employee-attrition

2.Perfrom Data Preprocessing

3.Model Building using Logistic Regression and Decision Tree and Random Forest

4.Calculate Performance metrics
"""

#Import the Libraries.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

#Importing the dataset.
df=pd.read_csv("Employee-Attrition.csv")

df.head()

df.shape

df.Age.value_counts()

df.info()

df.describe()

#Checking for Null Values.
df.isnull().any()

df.isnull().sum()

#Data Visualization.
sns.distplot(df["Age"])

df.corr()

df.head()

plt.subplots(figsize = (25,25))
sns.heatmap(df.corr(),annot=True)

sns.boxplot(df.	Age)

sns.boxplot(df.DailyRate	)

df.head()

x=df.iloc[:,1:4]
x.head()

y=df.Attrition
y.head()

#label encoding
from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
y=le.fit_transform(y)

#label encoding
from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
y_test=le.fit_transform(y_test)

y

y_test

#label encoding
from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
x.Attrition=le.fit_transform(x.Attrition)
x.head()

#label encoding
from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
x.BusinessTravel	=le.fit_transform(x.BusinessTravel	)
x.head()

#feature scaling
from sklearn.preprocessing import MinMaxScaler
ms=MinMaxScaler()
x_scaled=pd.DataFrame(ms.fit_transform(x),columns=x.columns)

x_scaled

#Splitting Data into Train and Test.
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x_scaled,y,test_size=0.2,random_state=0)



x_train.shape,x_test.shape,y_train.shape,y_test.shape

x_train.head()

from sklearn.linear_model import LogisticRegression
model=LogisticRegression()

model.fit(x_train,y_train)
pred=model.predict(x_test)
pred

y_test

df

"""# Evaluation of classification model"""

#Accuracy score
from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,roc_auc_score,roc_curve

accuracy_score(y_test,pred)

confusion_matrix(y_test,pred)

pd.crosstab(y_test,pred)

"""### Roc-AUC curve"""

probability=model.predict_proba(x_test)[:,1]
probability

y

y_test

# roc_curve
fpr,tpr,threshsholds = roc_curve(y_test,probability)

plt.plot(fpr,tpr)
plt.xlabel('FPR')
plt.ylabel('TPR')
plt.title('ROC CURVE')
plt.show()

"""DecisionTreeClassifier"""

from sklearn.tree import DecisionTreeClassifier
dtc=DecisionTreeClassifier()

dtc.fit(x_train,y_train)

pred=dtc.predict(x_test)

pred

y_test

df

dtc.predict(ms.transform([[1,19,19000]]))

"""# Evaluation of classification model

"""

#Accuracy score
from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,roc_auc_score,roc_curve

#label encoding
from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
y=le.fit_transform(y)
#label encoding
from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
y_test=le.fit_transform(y_test)

y_test

accuracy_score(y_test,pred)

confusion_matrix(y_test,pred)

pd.crosstab(y_test,pred)

print(classification_report(y_test,pred))

"""### Roc-AUC curve"""

probability=dtc.predict_proba(x_test)[:,1]

probability

fpr,tpr,thresholds =  roc_curve(y_test,probability)

plt.plot(fpr,tpr)
plt.xlabel('FPR')
plt.ylabel('TPR')
plt.title('ROC CURVE')
plt.show()

from sklearn import tree
plt.figure(figsize=(25,15))
tree.plot_tree(dtc,filled=True)

from sklearn.model_selection import GridSearchCV
parameter={
 'criterion':['gini','entropy'],
  'splitter':['best','random'],
  'max_depth':[1,2,3,4,5],
  'max_features':['auto', 'sqrt', 'log2']

}

grid_search=GridSearchCV(estimator=dtc,param_grid=parameter,cv=5,scoring="accuracy")

grid_search.fit(x_train,y_train)

grid_search.best_params_

dtc_cv=DecisionTreeClassifier(criterion= 'entropy',
 max_depth=3,
 max_features='sqrt',
 splitter='best')
dtc_cv.fit(x_train,y_train)

pred=dtc_cv.predict(x_test)

print(classification_report(y_test,pred))

"""**RandomForestClassifier**"""

from sklearn.ensemble import RandomForestClassifier
rfc=RandomForestClassifier()

forest_params = [{'max_depth': list(range(10, 15)), 'max_features': list(range(0,14))}]

rfc_cv= GridSearchCV(rfc,param_grid=forest_params,cv=10,scoring="accuracy")

rfc_cv.fit(x_train,y_train)

pred=rfc_cv.predict(x_test)

print(classification_report(y_test,pred))

rfc_cv.best_params_